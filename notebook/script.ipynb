{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd89e64b",
   "metadata": {},
   "source": [
    "# Goal\n",
    "    1.Data Ingestion - Load PDFs, text files, HTML, CSVs\n",
    "    2.Advanced Chunking - Recursive, semantic\n",
    "    3.Vector Indexing - ChromaDB\n",
    "    4.Hybrid Search - Dense (embeddings) + Sparse (BM25)\n",
    "    5.Re-ranking - Cohere API & Cross-Encoder models\n",
    "    6.Query Transformation - Multi-query, HyDE, Step-back prompting\n",
    "    7.Context Compression - LLM-based relevance filtering\n",
    "    8.Generation with Citations - Answers with source attribution\n",
    "    9.Evaluation Metrics - MRR, Recall@K, answer quality\n",
    "    10.Complete Orchestration - Easy-to-use pipeline class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db467b2",
   "metadata": {},
   "source": [
    "## 1.Data Ingestion - Load PDFs, text files, HTML, CSVs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "630c951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93e8389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders import (PyPDFLoader,TextLoader,Docx2txtLoader,DirectoryLoader,UnstructuredHTMLLoader,CSVLoader)\n",
    "from typing import List,Dict,Tuple\n",
    "import re\n",
    "\n",
    "class DataIngestion:\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_pdfs(file_path:str):\n",
    "        loader=PyPDFLoader(file_path)\n",
    "        return loader.load()\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_text(file_path:str):\n",
    "        loader=TextLoader(file_path)\n",
    "        return loader.load()\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_directory(directory_path:str,glob_pattern:str='**/*.pdf'):\n",
    "        loader=DirectoryLoader(\n",
    "            directory_path,\n",
    "            glob=glob_pattern,\n",
    "            loader_cls=PyPDFLoader,\n",
    "            show_progress=True\n",
    "        )\n",
    "        return loader.load()\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_docx(file_path:str):\n",
    "        loader=Docx2txtLoader(file_path)\n",
    "        return loader.load()\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_text(text:str)->str:\n",
    "        text=re.sub(r\"\\s+\",' ',text)\n",
    "        text=re.sub(r'[^\\w\\s\\.\\?\\!\\-\\:\\;]','',text)\n",
    "        \n",
    "        return text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ff72b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 7/35 [00:09<00:34,  1.25s/it]Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      " 77%|███████▋  | 27/35 [00:51<00:07,  1.02it/s]Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 51 0 (offset 0)\n",
      "Ignoring wrong pointing object 71 0 (offset 0)\n",
      "100%|██████████| 35/35 [01:07<00:00,  1.93s/it]\n"
     ]
    }
   ],
   "source": [
    "document=DataIngestion.load_directory(r'C:\\Users\\evilk\\OneDrive\\Desktop\\Projects\\RAG-Complete-Pipeline\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37738179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1608\n"
     ]
    }
   ],
   "source": [
    "print(len(document))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82d2ce",
   "metadata": {},
   "source": [
    "## 2.Advanced Chunking - Recursive, semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4444ecf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import (RecursiveCharacterTextSplitter,CharacterTextSplitter)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.schema import Document\n",
    "import numpy as np\n",
    "\n",
    "class Chunking:\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def recursive_chunking(documents,chunk_size=1000,chunk_overlap=200):\n",
    "        textSplitter=RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"]\n",
    "        )\n",
    "        return textSplitter.split_documents(documents)\n",
    "    \n",
    "    @staticmethod\n",
    "    def semantic_chunking(documents,embedding,chunk_size=1000):\n",
    "         chunks=[]\n",
    "         model=SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "         \n",
    "         for doc in documents:\n",
    "             sentences=re.split(r'(?<=[.!?])\\s+',doc.page_content)\n",
    "             \n",
    "             if len(sentences)<=1:\n",
    "                 chunks.append(doc)\n",
    "                 continue\n",
    "             \n",
    "             embedding_array=model.encode(sentences)\n",
    "             \n",
    "             similarities=[]\n",
    "             for i in range(len(embedding_array)-1):\n",
    "                 sim=np.dot(embedding_array[i],embedding_array[i+1])\n",
    "                 similarities.append(sim)\n",
    "                 \n",
    "             threshold=np.percentile(similarities,30)\n",
    "             \n",
    "             current_chunk=[]\n",
    "             for i,sentence in enumerate(sentences):\n",
    "                 current_chunk.append(sentence)\n",
    "                 \n",
    "                 if i <len(similarities) and similarities[i]<threshold:\n",
    "                     chunk_text=' '.join(current_chunk)\n",
    "                     if len(chunk_text)>chunk_size:\n",
    "                         chunks.append(Document(\n",
    "                             page_content=chunk_text,\n",
    "                             metadata=doc.metadata\n",
    "                         ))\n",
    "                         current_chunk=[]\n",
    "                         \n",
    "             if current_chunk:\n",
    "                chunks.append(Document(\n",
    "                    page_content=' '.join(current_chunk),\n",
    "                    metadata=doc.metadata\n",
    "                ))\n",
    "         return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce27889b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Salary Risk The present value of the defined plan liability is calculated by reference to the future salaries \n",
      "of plan participants. As such, an increase in the salary of the plan participants will increase the \n",
      "plan's liability.\n",
      "  29.2 Share Based Payments\n",
      "   a) Scheme details\n",
      "    The Company has Employees’ Stock Option Scheme i.e. ESOS-2017 under which options have been granted at the \n",
      "exercise price of C 10 per share to be vested from time to time on the basis of performance and other eligibility criteria. \n",
      "Details of number of options outstanding have been tabulated below: \n",
      "Financial Year\n",
      "(Year of Grant)\n",
      "Number of Options Outstanding\n",
      "Financial Year of Vesting Exercise \n",
      "Price (K)\n",
      "Range of Fair value at Grant \n",
      "Date (K)\n",
      "As at  \n",
      "31st March, \n",
      "2024\n",
      "As at\n",
      "31st March, \n",
      "2023\n",
      "ESOS - 2017\n",
      "Details of Employee Stock Options granted from 1st April, 2020 to 31st March, 2024\n",
      "2020-21 2,00,000 2,00,000 2021-22 to 2024-25 10.00 2,133.40 - 2,151.90' metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.5 (Windows)', 'creationdate': '2024-08-22T14:10:09+05:30', 'moddate': '2024-08-22T14:48:11+05:30', 'trapped': '/False', 'source': 'C:\\\\Users\\\\evilk\\\\OneDrive\\\\Desktop\\\\Projects\\\\RAG-Complete-Pipeline\\\\data\\\\Finance policy\\\\standalone.pdf', 'total_pages': 86, 'page': 51, 'page_label': '52'}\n"
     ]
    }
   ],
   "source": [
    "chunks=Chunking.recursive_chunking(document)\n",
    "print(chunks[1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319cf81",
   "metadata": {},
   "source": [
    "## 3.Vector Indexing - ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac57bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.vectorstores import FAISS,Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "class Embeddings:\n",
    "    \n",
    "    def __init__(self,model_name='all-MiniLM-L6-v2'):\n",
    "        \n",
    "        self.embeddings=HuggingFaceEmbeddings(\n",
    "            model_name=f\"sentence-transformers/{model_name}\",\n",
    "            model_kwargs={'device':'cuda'},\n",
    "            encode_kwargs={'normalize_embeddings':True}\n",
    "        )\n",
    "        \n",
    "    def create_chroma_db(self,chunks,persist_directory=\"../chroma_db\"):\n",
    "        vectordb=Chroma.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=persist_directory\n",
    "        )\n",
    "        return vectordb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a61f0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evilk\\AppData\\Local\\Temp\\ipykernel_8748\\3264418004.py:10: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings=HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "emb=Embeddings()\n",
    "vectordb=emb.create_chroma_db(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3a676",
   "metadata": {},
   "source": [
    "## 4.Hybrid Search - Dense (embeddings) + Sparse (BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbc981e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n",
    "class HybridRetriever:\n",
    "    \n",
    "    def __init__(self,vectorstore,documents):\n",
    "        self.vectorstore=vectorstore\n",
    "        self.documents=documents\n",
    "        \n",
    "        tokenized_docs=[doc.page_content.lower().split() for doc in documents]\n",
    "        self.bm25=BM25Okapi(tokenized_docs)\n",
    "        print(f\"Hybrid Retriever ready with {len(documents)} documents\")\n",
    "        \n",
    "        \n",
    "    def retrieve(self,query:str,k=10,alpha=0.5):\n",
    "        \n",
    "        # Vector Search \n",
    "        dense_results=self.vectorstore.similarity_search_with_score(query,k=k*2)\n",
    "        \n",
    "        # BM25 Search\n",
    "        tokenized_query=query.lower().split()\n",
    "        bm25_scores=self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        #Normalized Scores between 0-1 \n",
    "        dense_scores=np.array([1/(1+score) for _,score in dense_results])\n",
    "        if dense_scores.max()>dense_scores.min():\n",
    "            dense_scores=(dense_scores-dense_scores.min())/(dense_scores.max()-dense_scores.min())\n",
    "            \n",
    "        if bm25_scores.max()>bm25_scores.min():\n",
    "            bm25_scores=(bm25_scores-bm25_scores.min())/(bm25_scores.max()-bm25_scores.min())\n",
    "            \n",
    "        doc_scores={}\n",
    "        # ADD dense scores\n",
    "        for i, (doc, _) in enumerate(dense_results):\n",
    "            doc_id=id(doc)\n",
    "            doc_scores[doc_id]={'doc':doc,'score':alpha*dense_scores[i]}\n",
    "            \n",
    "        #ADD Sparse scores\n",
    "        for i,doc in enumerate(self.documents):\n",
    "            doc_id=id(doc)\n",
    "            if doc_id in doc_scores:\n",
    "                doc_scores[doc_id]['score']+=(1-alpha)*bm25_scores[i]\n",
    "            else:\n",
    "                doc_scores[doc_id]={'doc':doc,'score':(1-alpha)*bm25_scores[i]}\n",
    "                \n",
    "        # Sort by combined score \n",
    "        sorted_docs=sorted(doc_scores.values(),key=lambda x:x['score'],reverse=True)[:k]\n",
    "        \n",
    "        return[(item['doc'],item['score']) for item in sorted_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56bb7520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Retriever ready with 4031 documents\n",
      "0.6   • Absence from place of duty without permission. \n",
      "• Obtaining or attempting to obtain leave or absen\n",
      "0.6   • Absence from place of duty without permission. \n",
      "• Obtaining or attempting to obtain leave or absen\n",
      "0.6   • Absence from place of duty without permission. \n",
      "• Obtaining or attempting to obtain leave or absen\n",
      "0.4   4. TRAVELLING ALLOWANCES \n",
      " \n",
      "4.1 TRANSFER  GRANT \n",
      "Employees will be entitled to one month basic pay p\n",
      "0.3996287450278538   STANDARD OPERATING PROCEDURE – HR                                                                   \n"
     ]
    }
   ],
   "source": [
    "hybrid = HybridRetriever(vectorstore=vectordb, documents=chunks)\n",
    "\n",
    "query = \"company leave policy for new employees\"\n",
    "results = hybrid.retrieve(query, k=5, alpha=0.6)\n",
    "\n",
    "for doc, score in results:\n",
    "    print(score,\" \",doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c13658",
   "metadata": {},
   "source": [
    "##  5.Re-ranking - Cohere API & Cross-Encoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0435e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "class ReRanker:\n",
    "    \n",
    "    def __init__(self,model_name=\"cross-encoder/ms-marco-MiniLM-L-6-v2\"):\n",
    "        \n",
    "        print(f\"Loading re-ranker model: {model_name}...\")\n",
    "        self.model=CrossEncoder(model_name)\n",
    "        print(\"Re-Ranker loaded\")\n",
    "        \n",
    "    def rerank(self,query:str,documents:List,top_n=5):\n",
    "        \n",
    "        pairs=[[query,doc.page_content] for doc in documents]\n",
    "        \n",
    "        scores=self.model.predict(pairs)\n",
    "        \n",
    "        scored_docs=list(zip(documents,scores))\n",
    "        scored_docs.sort(key=lambda x : x[1],reverse=True)\n",
    "        \n",
    "        return [doc for doc,_ in scored_docs[:top_n]]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60bafc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading re-ranker model: cross-encoder/ms-marco-MiniLM-L-6-v2...\n",
      "Re-Ranker loaded\n",
      "page_content='• Absence from place of duty without permission. \n",
      "• Obtaining or attempting to obtain leave or absence on false \n",
      "pretense. \n",
      "• Refusal to work over time. \n",
      "• Sexual harassment of individuals such as passing of sexual remark \n",
      "and verbal abuse. \n",
      "• Unwelcome physical contact or demand for sexual favors. \n",
      "• Habitual breach of any Standing Orders or any law applicable to the \n",
      "hospital or any rules made hereunder. \n",
      " \n",
      "H. LEAVE POLICY FOR EMPLOYEES \n",
      "To provide and regulate employees' time off from work for personal \n",
      "purposes Metro has put in place a \" Leave Policy\" applicable to \n",
      "Metro employees on the regular rolls of the company. Leave \n",
      "entitlements are provided to enable employees to:- \n",
      "• Rest and recover in case of illness \n",
      "• Attend personal affairs \n",
      "• Take vacations for rest and rejuvenation \n",
      "SL/CL/SPL entitlements coincide with and are determined for the \n",
      "calendar year' January-December \" These would be pro-rated for \n",
      "employees joining or leaving during the year. \n",
      "EL will be generated on the basis of Date of Joining. A weekend, \n",
      "falling in between the leave period, would be counted as a part of \n",
      "leave. Leave records are maintained by the HR Department. \n",
      "CASUAL LEAVE: \n",
      "Casual leave (CL) entitlement is 7 days per annum. Casual leave can \n",
      "be availed after completion of 3 months from date of joining for a' metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2024-01-19T06:42:54+00:00', 'author': 'Microsoft account', 'moddate': '2024-01-19T06:42:58+00:00', 'source': 'C:\\\\Users\\\\evilk\\\\OneDrive\\\\Desktop\\\\Projects\\\\RAG-Complete-Pipeline\\\\data\\\\Hr Policy\\\\HR-POLICIES-1-1-1.pdf', 'total_pages': 47, 'page': 16, 'page_label': '17'}\n"
     ]
    }
   ],
   "source": [
    "reranker=ReRanker()\n",
    "top_docs=reranker.rerank(query,document,top_n=5)\n",
    "print(top_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a5713fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='LEAVES- STIPENDARY/ TRAINEE/ INTERNS \n",
      "Staff under this category are not entitled for any hospital/ employee \n",
      "benefits. \n",
      "Procedure For Application of Leave: \n",
      "The employee shall apply leave online & get it approved from his \n",
      "Departmental Head, prior to proceeding on leave, In cases of \n",
      "emergency, leave approval may be taken over the telephone and \n",
      "should be applied online immediately upon return. In such cases it \n",
      "will be the responsibility of the employee to regularize his / her \n",
      "absence. In emergency leave, the HOD will intimate in writing/mail \n",
      "to HR Department regarding the leave of the concerned employee as \n",
      "soon as he receives the information of leave. If any staff is taking \n",
      "leave without prior information, such applications will not be \n",
      "accepted and emplovee will be marked absent from duty for 3 days \n",
      "(1+2). If such leave has been approved, employee's leave records will \n",
      "be updated accordingly. \n",
      "Notes: \n",
      "• Late presentation of Leave will not be accepted. \n",
      "• If an employee is taking leave i.e. CL on Saturday and Monday, then \n",
      "Sunday will not be counted as leave but in case of SPL/Sick leave/EL \n",
      "sunday will be counted as leave. \n",
      "• Visiting Consultants (fee for services)/Stipendary/ Interns/Trainees \n",
      "are not entitled for any type of leaves. \n",
      "•Employee working on Holi and Diwali will be paid extra. \n",
      "All HOD's/Section Incharges should approve leave/ short leave and \n",
      "update roster in 24 hours. Discripency in salary days calculated due \n",
      "to above error will not be considered.' metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft® Word 2016', 'creationdate': '2024-01-19T06:42:54+00:00', 'author': 'Microsoft account', 'moddate': '2024-01-19T06:42:58+00:00', 'source': 'C:\\\\Users\\\\evilk\\\\OneDrive\\\\Desktop\\\\Projects\\\\RAG-Complete-Pipeline\\\\data\\\\Hr Policy\\\\HR-POLICIES-1-1-1.pdf', 'total_pages': 47, 'page': 19, 'page_label': '20'}\n"
     ]
    }
   ],
   "source": [
    "query= \"What’s the leave policy for interns?\"\n",
    "top_docs=reranker.rerank(query,document,top_n=5)\n",
    "print(top_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d6244e",
   "metadata": {},
   "source": [
    "## 6.Query Transformation - Multi-query, HyDE, Step-back prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a6830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe980e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b20f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96522c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
