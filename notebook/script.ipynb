{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd89e64b",
   "metadata": {},
   "source": [
    "# Goal\n",
    "    1.Data Ingestion - Load PDFs, text files, HTML, CSVs\n",
    "    2.Advanced Chunking - Recursive, semantic\n",
    "    3.Vector Indexing - ChromaDB\n",
    "    4.Hybrid Search - Dense (embeddings) + Sparse (BM25)\n",
    "    5.Re-ranking - Cohere API & Cross-Encoder models\n",
    "    6.Query Transformation - Multi-query, HyDE, Step-back prompting\n",
    "    7.Context Compression - LLM-based relevance filtering\n",
    "    8.Generation with Citations - Answers with source attribution\n",
    "    9.Evaluation Metrics - MRR, Recall@K, answer quality\n",
    "    10.Complete Orchestration - Easy-to-use pipeline class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db467b2",
   "metadata": {},
   "source": [
    "## 1.Data Ingestion - Load PDFs, text files, HTML, CSVs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e8389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.document_loaders import (PyPDFLoader,TextLoader,Docx2txtLoader,DirectoryLoader,UnstructuredHTMLLoader,CSVLoader)\n",
    "from typing import List,Dict,Tuple\n",
    "import re\n",
    "\n",
    "class DataIngestion:\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_pdfs(file_path:str):\n",
    "        loader=PyPDFLoader(file_path)\n",
    "        return loader.load()\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_text(file_path:str):\n",
    "        loader=TextLoader(file_path)\n",
    "        return loader.load()\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_directory(directory_path:str,glob_pattern:str='**/*.pdf'):\n",
    "        loader=DirectoryLoader(\n",
    "            directory_path,\n",
    "            glob=glob_pattern,\n",
    "            loader_cls=PyPDFLoader,\n",
    "            show_progress=True\n",
    "        )\n",
    "        return loader.load()\n",
    "        \n",
    "    @staticmethod\n",
    "    def load_docx(file_path:str):\n",
    "        loader=Docx2txtLoader(file_path)\n",
    "        return loader.load()\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocess_text(text:str)->str:\n",
    "        text=re.sub(r\"\\s+\",' ',text)\n",
    "        text=re.sub(r'[^\\w\\s\\.\\?\\!\\-\\:\\;]','',text)\n",
    "        \n",
    "        return text.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff72b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 7/35 [00:10<00:36,  1.31s/it]Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 26 0 (offset 0)\n",
      "Ignoring wrong pointing object 28 0 (offset 0)\n",
      " 77%|███████▋  | 27/35 [00:44<00:07,  1.14it/s]Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 45 0 (offset 0)\n",
      "Ignoring wrong pointing object 48 0 (offset 0)\n",
      "Ignoring wrong pointing object 51 0 (offset 0)\n",
      "Ignoring wrong pointing object 71 0 (offset 0)\n",
      "100%|██████████| 35/35 [00:58<00:00,  1.68s/it]\n"
     ]
    }
   ],
   "source": [
    "document=DataIngestion.load_directory(r'C:\\Users\\evilk\\OneDrive\\Desktop\\Projects\\RAG-Complete-Pipeline\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37738179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1608\n"
     ]
    }
   ],
   "source": [
    "print(len(document))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec82d2ce",
   "metadata": {},
   "source": [
    "## 2.Advanced Chunking - Recursive, semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4444ecf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evilk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\triton\\windows_utils.py:441: UserWarning: Failed to find CUDA.\n",
      "  warnings.warn(\"Failed to find CUDA.\")\n",
      "W1021 21:54:30.039000 11636 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import (RecursiveCharacterTextSplitter,CharacterTextSplitter)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.schema import Document\n",
    "import numpy as np\n",
    "\n",
    "class Chunking:\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def recursive_chunking(documents,chunk_size=1000,chunk_overlap=200):\n",
    "        textSplitter=RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"]\n",
    "        )\n",
    "        return textSplitter.split_documents(documents)\n",
    "    \n",
    "    @staticmethod\n",
    "    def semantic_chunking(documents,embedding,chunk_size=1000):\n",
    "         chunks=[]\n",
    "         model=SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "         \n",
    "         for doc in documents:\n",
    "             sentences=re.split(r'(?<=[.!?])\\s+',doc.page_content)\n",
    "             \n",
    "             if len(sentences)<=1:\n",
    "                 chunks.append(doc)\n",
    "                 continue\n",
    "             \n",
    "             embedding_array=model.encode(sentences)\n",
    "             \n",
    "             similarities=[]\n",
    "             for i in range(len(embedding_array)-1):\n",
    "                 sim=np.dot(embedding_array[i],embedding_array[i+1])\n",
    "                 similarities.append(sim)\n",
    "                 \n",
    "             threshold=np.percentile(similarities,30)\n",
    "             \n",
    "             current_chunk=[]\n",
    "             for i,sentence in enumerate(sentences):\n",
    "                 current_chunk.append(sentence)\n",
    "                 \n",
    "                 if i <len(similarities) and similarities[i]<threshold:\n",
    "                     chunk_text=' '.join(current_chunk)\n",
    "                     if len(chunk_text)>chunk_size:\n",
    "                         chunks.append(Document(\n",
    "                             page_content=chunk_text,\n",
    "                             metadata=doc.metadata\n",
    "                         ))\n",
    "                         current_chunk=[]\n",
    "                         \n",
    "             if current_chunk:\n",
    "                chunks.append(Document(\n",
    "                    page_content=' '.join(current_chunk),\n",
    "                    metadata=doc.metadata\n",
    "                ))\n",
    "         return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce27889b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Salary Risk The present value of the defined plan liability is calculated by reference to the future salaries \n",
      "of plan participants. As such, an increase in the salary of the plan participants will increase the \n",
      "plan's liability.\n",
      "  29.2 Share Based Payments\n",
      "   a) Scheme details\n",
      "    The Company has Employees’ Stock Option Scheme i.e. ESOS-2017 under which options have been granted at the \n",
      "exercise price of C 10 per share to be vested from time to time on the basis of performance and other eligibility criteria. \n",
      "Details of number of options outstanding have been tabulated below: \n",
      "Financial Year\n",
      "(Year of Grant)\n",
      "Number of Options Outstanding\n",
      "Financial Year of Vesting Exercise \n",
      "Price (K)\n",
      "Range of Fair value at Grant \n",
      "Date (K)\n",
      "As at  \n",
      "31st March, \n",
      "2024\n",
      "As at\n",
      "31st March, \n",
      "2023\n",
      "ESOS - 2017\n",
      "Details of Employee Stock Options granted from 1st April, 2020 to 31st March, 2024\n",
      "2020-21 2,00,000 2,00,000 2021-22 to 2024-25 10.00 2,133.40 - 2,151.90' metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 19.5 (Windows)', 'creationdate': '2024-08-22T14:10:09+05:30', 'moddate': '2024-08-22T14:48:11+05:30', 'trapped': '/False', 'source': 'C:\\\\Users\\\\evilk\\\\OneDrive\\\\Desktop\\\\Projects\\\\RAG-Complete-Pipeline\\\\data\\\\Finance policy\\\\standalone.pdf', 'total_pages': 86, 'page': 51, 'page_label': '52'}\n"
     ]
    }
   ],
   "source": [
    "chunks=Chunking.recursive_chunking(document)\n",
    "print(chunks[1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319cf81",
   "metadata": {},
   "source": [
    "## 3.Vector Indexing - ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac57bb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.vectorstores import FAISS,Chroma\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "\n",
    "class Embeddings:\n",
    "    \n",
    "    def __init__(self,model_name='all-MiniLM-L6-v2'):\n",
    "        \n",
    "        self.embeddings=HuggingFaceEmbeddings(\n",
    "            model_name=f\"sentence-transformers/{model_name}\",\n",
    "            model_kwargs={'device':'cuda'},\n",
    "            encode_kwargs={'normalize_embeddings':True}\n",
    "        )\n",
    "        \n",
    "    def create_chroma_db(self,chunks,persist_directory=\"../chroma_db\"):\n",
    "        vectordb=Chroma.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=persist_directory\n",
    "        )\n",
    "        return vectordb\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a61f0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evilk\\AppData\\Local\\Temp\\ipykernel_11636\\3264418004.py:10: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  self.embeddings=HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "emb=Embeddings()\n",
    "vectordb=emb.create_chroma_db(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab3a676",
   "metadata": {},
   "source": [
    "## 4.Hybrid Search - Dense (embeddings) + Sparse (BM25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbc981e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n",
    "class HybridRetriever:\n",
    "    \n",
    "    def __init__(self,vectorstore,documents):\n",
    "        self.vectorstore=vectorstore\n",
    "        self.documents=documents\n",
    "        \n",
    "        tokenized_docs=[doc.page_content.lower().split() for doc in documents]\n",
    "        self.bm25=BM25Okapi(tokenized_docs)\n",
    "        print(f\"Hybrid Retriever ready with {len(documents)} documents\")\n",
    "        \n",
    "        \n",
    "    def retrieve(self,query:str,k=10,alpha=0.5):\n",
    "        \n",
    "        # Vector Search \n",
    "        dense_results=self.vectorstore.similarity_search_with_score(query,k=k*2)\n",
    "        \n",
    "        # BM25 Search\n",
    "        tokenized_query=query.lower().split()\n",
    "        bm25_scores=self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        #Normalized Scores between 0-1 \n",
    "        dense_scores=np.array([1/(1+score) for _,score in dense_results])\n",
    "        if dense_scores.max()>dense_scores.min():\n",
    "            dense_scores=(dense_scores-dense_scores.min())/(dense_scores.max()-dense_scores.min())\n",
    "            \n",
    "        if bm25_scores.max()>bm25_scores.min():\n",
    "            bm25_scores=(bm25_scores-bm25_scores.min())/(bm25_scores.max()-bm25_scores.min())\n",
    "            \n",
    "        doc_scores={}\n",
    "        # ADD dense scores\n",
    "        for i, (doc, _) in enumerate(dense_results):\n",
    "            doc_id=id(doc)\n",
    "            doc_scores[doc_id]={'doc':doc,'score':alpha*dense_scores[i]}\n",
    "            \n",
    "        #ADD Sparse scores\n",
    "        for i,doc in enumerate(self.documents):\n",
    "            doc_id=id(doc)\n",
    "            if doc_id in doc_scores:\n",
    "                doc_scores[doc_id]['score']+=(1-alpha)*bm25_scores[i]\n",
    "            else:\n",
    "                doc_scores[doc_id]={'doc':doc,'score':(1-alpha)*bm25_scores[i]}\n",
    "                \n",
    "        # Sort by combined score \n",
    "        sorted_docs=sorted(doc_scores.values(),key=lambda x:x['score'],reverse=True)[:k]\n",
    "        \n",
    "        return[(item['doc'],item['score']) for item in sorted_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56bb7520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Retriever ready with 4031 documents\n",
      "0.6   • Absence from place of duty without permission. \n",
      "• Obtaining or attempting to obtain leave or absen\n",
      "0.6   • Absence from place of duty without permission. \n",
      "• Obtaining or attempting to obtain leave or absen\n",
      "0.4   4. TRAVELLING ALLOWANCES \n",
      " \n",
      "4.1 TRANSFER  GRANT \n",
      "Employees will be entitled to one month basic pay p\n",
      "0.3996287450278538   STANDARD OPERATING PROCEDURE – HR                                                                   \n",
      "0.39644279161865015   This will be effective October 1 2016. \n",
      " \n",
      "Maternity leave \n",
      " \n",
      "Maternity Leave Benefit for the woman e\n"
     ]
    }
   ],
   "source": [
    "hybrid = HybridRetriever(vectorstore=vectordb, documents=chunks)\n",
    "\n",
    "query = \"company leave policy for new employees\"\n",
    "results = hybrid.retrieve(query, k=5, alpha=0.6)\n",
    "\n",
    "for doc, score in results:\n",
    "    print(score,\" \",doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c13658",
   "metadata": {},
   "source": [
    "##  5.Re-ranking - Cohere API & Cross-Encoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435e75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bafc30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5713fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a6830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe980e77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b20f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96522c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
